{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 2: network models\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[Hermina Petric Maretic](https://people.epfl.ch/hermina.petricmaretic), [EPFL LTS4](https://lts4.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: `4`\n",
    "* Students: `Julien Berger, Jérémy Jayet, Hana Samet, Mathieu Shiva`\n",
    "* Dataset: `IMDb Films and Crew`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* In the first part, you cannot import any other library than we imported. In the second part, you are allowed to import any library you want.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The purpose of this milestone is to explore various random network models, analyse their properties and compare them to your network. In the first part of the milestone you will implement two random graph models and try to fit them to your network. In this part you are not allowed to use any additional package. In the second part of the milestone you will choose a third random graph model that you think shares some properties with your network. You will be allowed to use additional packages to construct this network, but you must explain your network choice. Finally, make your code as clean as possible, and keep your textual answers short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0\n",
    "\n",
    "Import the adjacency matrix of your graph that you constructed in milestone 1, as well as the number of nodes and edges of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import queue as Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency =  np.load('./data/adjacency.npy')\n",
    "\n",
    "adjacency[adjacency <2]=0\n",
    "\n",
    "n_nodes =  adjacency.shape[0]\n",
    "n_edges =  np.count_nonzero(adjacency)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "**For the computation of this part of the milestone you are only allowed to use the packages that have been imported in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We moved the code above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Create a function that constructs an Erdős–Rényi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erdos_renyi(n, p, seed=None):\n",
    "    \"\"\"Create an instance from the Erdos-Renyi graph model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    p: float\n",
    "        Edge probability. A number between 0 and 1.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    adjacency = np.zeros((n,n), dtype=float)\n",
    "\n",
    "    for i in range(1,n):\n",
    "        for j in range(0,i):\n",
    "            adjacency[i,j] = (np.random.random()<p)\n",
    "            adjacency[j,i] = adjacency[i,j]\n",
    "\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(5, 0.6, 9765)\n",
    "plt.spy(er)\n",
    "plt.title('Erdos-Renyi (5, 0.6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(10, 0.4, 7648)\n",
    "plt.spy(er)\n",
    "plt.title('Erdos-Renyi (10, 0.4)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Use the function to create a random Erdos-Renyi graph. Choose the parameters such that number of nodes is the same as in your graph, and the number of edges similar. You don't need to set the random seed. Comment on your choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = n_edges/((n_nodes*n_nodes/2)-n_nodes)\n",
    "\n",
    "er = erdos_renyi(n_nodes, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes is *n_nodes*, given by the size of the first (or the second) dimension of the adjacency matrix. The probability *p* is equal to the number of edges divided by the number of possible edges, formally : $p = \\frac{n_{edges}}{\\frac{n_{nodes}^2}{2}-n_{nodes}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Create a function that constructs a Barabási-Albert graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barabasi_albert(n, m, seed=None, m0=2):\n",
    "    \"\"\"Create an instance from the Barabasi-Albert graph model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    m: int\n",
    "        Number of edges to attach from a new node to existing nodes.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "     # Add m initial nodes (m0 in Lecture) \n",
    "    adjacency = np.zeros((n, n), dtype=int)\n",
    "    \n",
    "    #start with m0 nodes, with arbitrarily chosen links (with at least one link per node)\n",
    "    for i in range(m0):\n",
    "        node=random.randint(1, m0)\n",
    "        while (node==i):\n",
    "            node=random.randint(1, m0)\n",
    "            \n",
    "        adjacency[i,node]=1\n",
    "        adjacency[node,i]=1 \n",
    "\n",
    "    # List of existing nodes, with nodes repeated once for each adjacent edge \n",
    "    repeated_nodes=[] \n",
    "    #filling the repeated_node with the created m node \n",
    "    for i in range(m0):\n",
    "        tmp=sum(adjacency[i])\n",
    "        while (tmp>=0):\n",
    "            repeated_nodes.extend([i]) \n",
    "            tmp=tmp-1 \n",
    "    \n",
    "    # Start adding the other n-m nodes. The first node is m. \n",
    "    source=m0+1 \n",
    "    #The easiest way of picking nodes with probability proportional to their degree is to maintain a list\n",
    "    #of node labels where each node appears as many times as its degree is, \n",
    "    # and then just pick a random element from the list\n",
    "    if m0 < m : \n",
    "        m=m0 # m should always be smaller or equal to m0\n",
    "    while source<n: \n",
    "        # Now choose m nodes from the existing nodes \n",
    "        # Pick uniformly from repeated_nodes (preferential attachement) \n",
    "        targets = random.sample(repeated_nodes,m) \n",
    "        for i in targets:\n",
    "            adjacency[i,source]=1\n",
    "            adjacency[source,i]=1\n",
    "            repeated_nodes.extend([source]) \n",
    "            repeated_nodes.extend([i])\n",
    "        source += 1\n",
    "     \n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = barabasi_albert(5, 1, 9087)\n",
    "plt.spy(ba)\n",
    "plt.title('Barabasi-Albert (5, 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = barabasi_albert(10, 2, 8708)\n",
    "plt.spy(ba)\n",
    "plt.title('Barabasi-Albert (10, 2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Use the function to create a random Barabási-Albert graph. Choose the parameters such that number of nodes is the same as in your graph, and the number of edges similar. You don't need to set the random seed. Comment on your choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_nodes=t+m0\n",
    "#n_edges=m*t+m0\n",
    "\n",
    "m0=355 #  arbitrarily \n",
    "t=n_nodes-m0\n",
    "m=int((n_edges-m0)/t)\n",
    "print(m*t+m0)\n",
    "print(n_edges)\n",
    "ba = barabasi_albert(n_nodes, m ,8708,m0)\n",
    "plt.spy(ba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Compare the number of edges in all three networks (your real network, the Erdős–Rényi network, and the Barabási-Albert netowk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edges_er =  np.count_nonzero(er)/2\n",
    "n_edges_ba =  np.count_nonzero(ba)/2\n",
    "\n",
    "print(f'The original network contains {n_edges} edges.')\n",
    "print(f'The Erdős–Rényi network contains {n_edges_er} edges.') \n",
    "print(f'The Barabási-Albert network contains {n_edges_ba} edges.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Implement a function that computes the [Kullback–Leibler (KL) divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between two probability distributions.\n",
    "We'll use it to compare the degree distributions of networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    \"\"\"Compute the KL divergence between probability distributions of degrees of two networks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p: np.array\n",
    "        Probability distribution of degrees of the 1st graph.\n",
    "    q: np.array\n",
    "        Probability distribution of degrees of the 2nd graph.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    kl\n",
    "        The KL divergence between the two distributions.\n",
    "    \"\"\"\n",
    "    kl = 0;\n",
    "    \n",
    "    # To deal with p and q of different sizes\n",
    "    n = np.min([p.shape[0],q.shape[0]])\n",
    "    \n",
    "    for i in range(n):\n",
    "        if q[i] != 0 and p[i]!=0:\n",
    "            kl = kl + p[i]*np.log(p[i]/q[i])\n",
    "    \n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_test = np.array([0.2, 0.2, 0.2, 0.4])\n",
    "q_test = np.array([0.3, 0.3, 0.1, 0.3])\n",
    "kl_divergence(p_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Compare the degree distribution of your network to each of the two synthetic ones, in terms of KL divergence. **Hint:** Make sure you normalise your degree distributions to make them valid probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the find_components function that we had to create during the first milestone.\n",
    "import src.find_components as fcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_distribution(p,nb_split):\n",
    "    \"\"\"Returns the normalized probability distribution linearly separated into a certain number of splits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p: numpy array\n",
    "        The degree distribution \n",
    "        \n",
    "    nb_split : int\n",
    "        the number of splits used to create the normalized probability distribution\n",
    "        (think of it as the number of bars in the histogram)  \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array of size nb_split\n",
    "        the normalized probability distribution of the degree.\n",
    "    \"\"\"\n",
    "    #we normalize the initial distribution of degree\n",
    "    p=p/max(p)\n",
    "    p_norm=np.zeros((nb_split), dtype=int)\n",
    "    \n",
    "    #we divide de interval between 0 and 1 in nb_split parts and we count the number of degrees in each interval\n",
    "    for i in range(nb_split):\n",
    "        p_split=np.where(np.logical_and((p>i/nb_split), p<=(i+1)/nb_split))\n",
    "        p_norm[i]=np.shape(p_split)[1]\n",
    "    \n",
    "    #we now have a degree distribution which is discretised in nb_splits elements.\n",
    "    #we normalize this degree distribution to obtain the probability density of degree distribution\n",
    "\n",
    "    p_probability_distrib=p_norm/sum(p_norm)\n",
    "    \n",
    "    \n",
    "   # #p_new_distrib is the normalized degree distribution in the new space (degrees between 0 and 1 )\n",
    "   # normalized_range=np.arange(1,nb_split+1)/nb_split\n",
    "   # p_new_distrib=[]\n",
    "   # for i in range(p_norm.shape[0]):\n",
    "   #     for j in range(np.transpose(p_norm)[i]):\n",
    "   #         p_new_distrib=np.append(p_new_distrib,normalized_range[i])\n",
    "             \n",
    "    #weights_p = p_norm / float(sum(p_norm))\n",
    "    #weights_q = q_norm/ float(sum(q_norm))\n",
    "    #weights_p = np.ones_like(p_new_distrib) / float(p_new_distrib.shape[0])\n",
    "    #weights_q = np.ones_like(q_new_distrib) / float(q_new_distrib.shape[0])      \n",
    "    \n",
    "\n",
    "    return p_probability_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We need to have a connected graph in order to find the kl divergence.\n",
    "# As our network is not connected, we use the adjacency matrix of the largest connected component instead\n",
    "\n",
    "# The first element of the connectedIndices matrix is a vector of length equal to n_nodes\n",
    "# The value of its elements is 1 if the element is in the largest connected componenent and 0 if it is not\n",
    "connectedIndices = fcomp.find_components(adjacency)\n",
    "biggestComponentSize = np.amax(np.sum(connectedIndices, axis=1))\n",
    "\n",
    "# get the adjacency matrix of the largest connected component of our network\n",
    "indx=np.array(range(n_nodes),dtype=int)\n",
    "indx=connectedIndices[0].astype(int)*indx\n",
    "indx_without_zeros=np.unique(indx)\n",
    "\n",
    "# take the unweighted version of the adjacency matrix\n",
    "Biggest_component=adjacency[indx_without_zeros,:][:,indx_without_zeros]\n",
    "Biggest_component[Biggest_component!=0]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the normalized degree distribution for the largest connected component \n",
    "#of the original graph and for the ER graph\n",
    "\n",
    "#We separate the probability distribution into 12 boxes \n",
    "#(if we take more the precision is not good enough and we get divisions by 0)\n",
    "nb_split=50\n",
    "\n",
    "degree_er = np.sum(er, axis=0)\n",
    "degree_er = degree_er/sum(degree_er)\n",
    "\n",
    "degree_biggest = np.sum(Biggest_component, axis=0)\n",
    "degree_biggest=degree_biggest/sum(degree_biggest)\n",
    "\n",
    "#Transform the degree distribution into probability distribution\n",
    "prob_distrib_er=probability_distribution(degree_er,nb_split)\n",
    "prob_distrib_biggest=probability_distribution(degree_biggest,nb_split)\n",
    "\n",
    "#plt.hist(prob_distrib_biggest, weights=weights, rwidth=.5, bins=50);\n",
    "tmp=kl_divergence(prob_distrib_er,prob_distrib_biggest)\n",
    "\n",
    "print('The KL divergence between the original graph and the Erdős–Rényi graph is equal to {:.5f}'.format(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the normalized degree distribution for BA graph\n",
    "degree_ba = np.sum(ba, axis=0)\n",
    "degree_ba=degree_ba/sum(degree_ba)\n",
    "\n",
    "#Transform the degree distribution into probability distribution\n",
    "prob_distrib_ba=probability_distribution(degree_ba,nb_split)\n",
    "\n",
    "tmp=kl_divergence(prob_distrib_ba,prob_distrib_biggest)\n",
    "print('The KL divergence between the original graph and the Barabási-Albert graph is equal to {:.5f}'.format(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Plot the degree distribution historgrams for all three networks. Are they consistent with the KL divergence results? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The histogram of our original network\n",
    "\n",
    "# we use the unweighted adjacency matrix\n",
    "unweighted_adjacency=adjacency\n",
    "unweighted_adjacency[unweighted_adjacency != 0] = 1;\n",
    "degree = np.sum(unweighted_adjacency, axis=0);\n",
    "weights = np.ones_like(degree) / float(n_nodes)\n",
    "#plt.hist(degree, weights=weights, rwidth=.5);\n",
    "\n",
    "#The histogram of the Erdos-Renyi graph\n",
    "degree_er = np.sum(er, axis=0);\n",
    "weights = np.ones_like(degree_er) / float(n_nodes)\n",
    "#plt.hist(degree_er, weights=weights, rwidth=.5);\n",
    "\n",
    "#The histogram of the Barabási-Albert graph\n",
    "degree_ba = np.sum(ba, axis=0);\n",
    "weights = np.ones_like(degree_ba) / float(n_nodes)\n",
    "#plt.hist(degree_ba, weights=weights, rwidth=.5);\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(131);\n",
    "plt.hist(degree, weights=weights, bins=20, rwidth=.5);\n",
    "plt.title('Original network');\n",
    "plt.axis([0,degree.max(),0,1])\n",
    "\n",
    "plt.subplot(132);\n",
    "plt.hist(degree_er, weights=weights, bins=20, rwidth=.5);\n",
    "plt.title('Erdos-Renyi Graph');\n",
    "plt.axis([0,degree_er.max(),0,1])\n",
    "\n",
    "plt.subplot(133);\n",
    "plt.hist(degree_ba, weights=weights,bins=20,  rwidth=.5);\n",
    "plt.title('Barabási-Albert Graph');\n",
    "plt.axis([0,degree_ba.max(),0,1])\n",
    "\n",
    "plt.suptitle('Degree distribution of the 3 graphs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the Barabási-Albert degree distribution looks similar to the original network distribution. We can also see that the Erdos-Renyi degree distribution is quite different from the other two.\n",
    "This is consistent since we obtain a lower KL divergence between the original graph and the BA graph than between the original graph and the ER graph. The KL divergence should be equal to 0 if two distributions are similar, so the lower the score, the more similar the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Imagine you got equal degree distributions. Would that guarantee you got the same graph? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, because the degree distribution doesn't give information on how the edges in the network are connected. For exemple if we take a simple example with 6 nodes, we can have the exact same degree distribution, but not the same graph.\n",
    "Let's consider the example below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A-B-C-D-E      and    A-B-C-D-E        both have degree distribution equal to (1,1,1,2,2,3) but the graphs are not similar.\n",
    "    |                   |\n",
    "    F                   F   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "**You are allowed to use any additional library here (e.g., NetworkX, PyGSP, etc.).** Be careful not to include something here and use it in part 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose a random network model that fits you network well. Explain your choice. \n",
    "\n",
    "**Hint:** Check lecture notes for different network models and their properties. Your choice should be made based on at least one property you'd expect to be similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 2 network models seen above, we think that the Barabasi-Albert model is the one that would fit our model the best. The first property that we expect to be similar is the degree distribution,that follows a scale-free trend, as seen in part 1.\n",
    "\n",
    "However, we first decided to test the configuration model. This choice is based on the degree distribution property, so we expect this model to have a similar density, number of connected components and diameter. As this model requires an initial degree distribution, the model that will be created will simply rewire the connections between the nodes. This means that parameters such as density or the number of single nodes should remain the same.\n",
    "\n",
    "We then modified the Barabasi-Albert model to have a non-connected graph that are formed following the growth and preferential attachment process. We expect to have a similar density and a similar number of nodes in the biggest component. We hope it would fit our initial network better and called this new model the \"random actor network model\".\n",
    "\n",
    "Comparing the properties that we will obtain for both, we will then choose the closest fit to the original graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Explain (in short) how the chosen model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The configuration model\n",
    "It creates a adjacency matrix of a network that has the same degree distribution as the desired original network.\n",
    "\n",
    "Starting from an initial degree distribution, you randomly pick two \"stubs\" and connect them together until every stub has been connected. This means that the degree distribution(and thus the number of edges) will be the same, but the adjacency matrix will be randomized.\n",
    "\n",
    "This model follows the growth process but respects the predefined degree distribution that is given as a parameter. It also follows the preferential attachment as in the node are tended to be linked to the more connected nodes but within the range the range of degree given in by the parameter.\n",
    "\n",
    "#### The random actor network model\n",
    "This model is a modified version of the Barabási-Albert model, but instead of adding a node with m links each time we add a node with a number of link m', taken from a normal distribution centered at m’ with a certain standard deviation that is given to the function as parameter. This enables us to have a scale free network that conserve the similarities obtained in part 1 but can be non-connected as our original graph and can have multiple connected components.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Create a random graph from that model, such that the number of nodes is the same as in your graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration_model(distrib,seed=None):\n",
    "    \"\"\"Create a configuration model from a predifined degree distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    distrib: numpy array\n",
    "        degree distribution\n",
    "\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    n_nodes=distrib.shape[0]\n",
    "    adjacency = np.zeros((n_nodes, n_nodes), dtype=int)\n",
    "    \n",
    "    #this list contains the nodes that still have unconnected stubs (so we first remove nodes with 0 degrees)    \n",
    "    linked_stubs=distrib\n",
    "    not_connected_nodes=np.nonzero(distrib)\n",
    "    not_connected_nodes=not_connected_nodes[0]\n",
    "    remaining_elements=not_connected_nodes.shape[0]\n",
    "    similar_iter=0;\n",
    "    while(similar_iter<300):\n",
    "        similar_iter=similar_iter+1\n",
    "        #we select two nodes that have unconnected stubs to link them\n",
    "        idx1=np.random.randint(0,remaining_elements,1)\n",
    "        idx2=np.random.randint(0,remaining_elements,1)\n",
    "        while (idx1==idx2):\n",
    "            idx2=np.random.randint(0,remaining_elements,1)\n",
    "            \n",
    "        node1=not_connected_nodes[idx1]\n",
    "        node2=not_connected_nodes[idx2]\n",
    "        \n",
    "        #we connect the nodes\n",
    "        adjacency[node1,node2]=1\n",
    "        adjacency[node2,node1]=1\n",
    "\n",
    "        #we check if all the stubs of the two node have been connected and if so, we remove them from the not_connected_nodes array\n",
    "        if sum(sum(adjacency[node1]))>=distrib[node1]:\n",
    "            not_connected_nodes=np.delete(not_connected_nodes,idx1)\n",
    "            remaining_elements=remaining_elements-1\n",
    "            similar_iter=0\n",
    "\n",
    "        if sum(sum(adjacency[node2]))>=distrib[node2]:\n",
    "            not_connected_nodes=np.delete(not_connected_nodes,idx2)\n",
    "            remaining_elements=remaining_elements-1\n",
    "            similar_iter=0\n",
    "        \n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of a configuration model with the same degree distribution.\n",
    "unweighted_adjacency=adjacency\n",
    "unweighted_adjacency[unweighted_adjacency!=0]=1\n",
    "degree_initial = np.sum(unweighted_adjacency, axis=0)\n",
    "\n",
    "configuration_adjacency=configuration_model(degree_initial,69)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_actor_network_model(n, m, std, seed=None, m0=2):\n",
    "    \"\"\"Create an instance from the Barabasi-Albert graph model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        Size of the graph.\n",
    "    m: int\n",
    "        Number of edges to attach from a new node to existing nodes.\n",
    "    seed: int (optional)\n",
    "        Seed for the random number generator. To get reproducible results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    adjacency\n",
    "        The adjacency matrix of a graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    # Add m initial nodes (m0 in Lecture) \n",
    "    adjacency = np.zeros((n, n), dtype=int)\n",
    "    \n",
    "    #start with m0 nodes, with arbitrarily chosen links (with at least one link per node)\n",
    "    for i in range(m0):\n",
    "        node=random.randint(1, m0)\n",
    "        while (node==i):\n",
    "            node=random.randint(1, m0)\n",
    "            \n",
    "        adjacency[i,node]=1\n",
    "        adjacency[node,i]=1 \n",
    "\n",
    "    # List of existing nodes, with nodes repeated once for each adjacent edge \n",
    "    repeated_nodes=[] \n",
    "    #filling the repeated_node with the created m node \n",
    "    for i in range(m0):\n",
    "        tmp=sum(adjacency[i])\n",
    "        while (tmp>=0):\n",
    "            repeated_nodes.extend([i]) \n",
    "            tmp=tmp-1 \n",
    "    \n",
    "    # Start adding the other n-m nodes. The first node is m. \n",
    "    source=m0+1 \n",
    "    #The easiest way of picking nodes with probability proportional to their degree is to maintain a list\n",
    "    #of node labels where each node appears as many times as its degree is, \n",
    "    # and then just pick a random element from the list\n",
    "    if m0 < m : \n",
    "        m=m0 # m should always be smaller or equal to m0\n",
    "    while source<n:\n",
    "        \n",
    "        # Choose a number of node from a normal distribution with a certain standard deviation\n",
    "        mLinksForAddedNode = int(np.around(np.random.normal(m,std)))\n",
    "        \n",
    "        # To avoid to ask for a negative number of samples\n",
    "        if mLinksForAddedNode < 1 :\n",
    "            mLinksForAddedNode = 0\n",
    "        \n",
    "        # Now choose m nodes from the existing nodes \n",
    "        # Pick uniformly from repeated_nodes (preferential attachement) \n",
    "        targets = np.random.choice(repeated_nodes,mLinksForAddedNode) \n",
    "        for i in targets:\n",
    "            adjacency[i,source]=1\n",
    "            adjacency[source,i]=1\n",
    "            repeated_nodes.extend([source]) \n",
    "            repeated_nodes.extend([i])\n",
    "        source += 1\n",
    "     \n",
    "    return adjacency\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "# Create the network\n",
    "std = 12 # We chose this value by iteration. We started with std=5 and went to std=14. We kept the best value.\n",
    "\n",
    "an = random_actor_network_model(n_nodes, m, std,8708,m0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Check the properties you expected to be similar, and compare to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of properties using network x\n",
    "G_original=nx.from_numpy_matrix(adjacency)\n",
    "G_config=nx.from_numpy_matrix(configuration_adjacency)\n",
    "\n",
    "print(\"density original network: %s\" % nx.density(G_original))\n",
    "print(\"density configuration network: %s\" % nx.density(G_config))\n",
    "\n",
    "print(\"Nb connected components original network: %d\" % nx.number_connected_components(G_original))\n",
    "print(\"Nb connected components configuration network: %d\" % nx.number_connected_components(G_config))\n",
    "\n",
    "#take the largest connected components and draw their diameters\n",
    "Gc_original = max(nx.connected_component_subgraphs(G_original), key=len)\n",
    "Gc_config = max(nx.connected_component_subgraphs(G_config), key=len)\n",
    "\n",
    "print(\"Nb nodes Giant component original network: %d\" % nx.number_of_nodes(Gc_original))\n",
    "print(\"Nb nodes Giant component configuration network: %d\" % nx.number_of_nodes(Gc_config))\n",
    "\n",
    "print(\"diameter original network: %d\" % nx.diameter(Gc_original))\n",
    "print(\"diameter configuration network: %d\" % nx.diameter(Gc_config))\n",
    "\n",
    "print(\"average clustering coefficient original network: %s\" % nx.average_clustering(Gc_original))\n",
    "print(\"average clustering coefficient configuration network: %s\" % nx.average_clustering(Gc_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of properties using network x\n",
    "G_original=nx.from_numpy_matrix(adjacency)\n",
    "G_an=nx.from_numpy_matrix(an)\n",
    "\n",
    "print(\"density original network: %s\" % nx.density(G_original))\n",
    "print(\"density new BA network: %s\" % nx.density(Gc_an))\n",
    "\n",
    "print(\"Nb connected components original network: %d\" % nx.number_connected_components(G_original))\n",
    "print(\"Nb connected components new BA network: %d\" % nx.number_connected_components(Gc_an))\n",
    "\n",
    "#take the largest connected components and draw their diameters\n",
    "Gc_original = max(nx.connected_component_subgraphs(G_original), key=len)\n",
    "Gc_config = max(nx.connected_component_subgraphs(Gc_an), key=len)\n",
    "\n",
    "print(\"Nb nodes Giant component original network: %d\" % nx.number_of_nodes(Gc_original))\n",
    "print(\"Nb nodes Giant component new BA network: %d\" % nx.number_of_nodes(Gc_an))\n",
    "\n",
    "print(\"diameter original network: %d\" % nx.diameter(Gc_original))\n",
    "print(\"diameter new BA network: %d\" % nx.diameter(Gc_an))\n",
    "\n",
    "print(\"average clustering coefficient original network: %s\" % nx.average_clustering(Gc_original))\n",
    "print(\"average clustering coefficient new BA network: %s\" % nx.average_clustering(Gc_an))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The histogram of the actor network model graph\n",
    "degree_an = np.sum(an, axis=0);\n",
    "weights = np.ones_like(degree_an) / float(n_nodes)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121);\n",
    "plt.hist(degree, weights=weights, bins=20, rwidth=.5);\n",
    "plt.title('Original network');\n",
    "plt.axis([0,degree.max(),0,1])\n",
    "\n",
    "plt.subplot(122);\n",
    "plt.hist(degree_an, weights=weights,bins=20,  rwidth=.5);\n",
    "plt.title(f'Actor network model\\nm0 = {m0}, m = {m}, std = {std}\\n');\n",
    "plt.axis([0,degree_an.max(),0,1])\n",
    "\n",
    "plt.suptitle(f'Degree distribution\\n\\n')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "n_edges_an =  np.count_nonzero(an)/2\n",
    "\n",
    "print(f'The original network contains {n_edges} edges.\\nThe actor network model contains {n_edges_an} edges.\\n')\n",
    "\n",
    "# We need to have a connected graph in order to find the kl divergence.\n",
    "# The model is not connected, we will find the largest connected component\n",
    "\n",
    "# The first element of the connectedIndices matrix is a vector of length equal to n_nodes\n",
    "# The value of its elements is 1 if the element is in the largest connected component and 0 if it is not\n",
    "connectedIndicesAn = fcomp.find_components(an)\n",
    "biggestComponentSizeAn = np.amax(np.sum(connectedIndicesAn, axis=1))\n",
    "\n",
    "print(f'The biggest component of the model has a size of {biggestComponentSizeAn}.\\\n",
    "In comparison, the biggest component of the original graph has a size of {biggestComponentSize} \\n')\n",
    "\n",
    "# get the adjacency matrix of the largest connected component of our network\n",
    "indx=np.array(range(n_nodes),dtype=int)\n",
    "indx=connectedIndicesAn[0].astype(int)*indx\n",
    "indx_without_zeros=np.unique(indx)\n",
    "\n",
    "# take the unweighted version of the adjacency matrix\n",
    "BiggestComponentAn = adjacency[indx_without_zeros,:][:,indx_without_zeros]\n",
    "BiggestComponentAn[BiggestComponentAn != 0] = 1\n",
    "\n",
    "degreeBiggestAn = np.sum(BiggestComponentAn, axis=0)\n",
    "degreeBiggestAn=degreeBiggestAn/sum(degreeBiggestAn)\n",
    "\n",
    "prob_distrib_biggestAn=probability_distribution(degreeBiggestAn,nb_split)\n",
    "\n",
    "#np.min(degreeBiggestAn)\n",
    "\n",
    "divergence = kl_divergence(prob_distrib_biggest,prob_distrib_biggestAn)\n",
    "\n",
    "print(f'The KL divergence between the original network and the model is {divergence}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the results what you expected? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying the two networks and comparing them to our original graph we did obtain the similar expected properties.\n",
    "\n",
    "With the *configuration model*, we have very close fit but since this model needs a predefined degree of distribution of the original graph as parameter, it is not ideal. So, We can say that the configuration model is far from being optimal and we can choose on the *random actor network model* to get a good fit with no prior knowledge of what the original graph looks like.\n",
    "\n",
    "With the *random actor network model*, we obtained close properties to our original graph, such as a similar degree distribution, about the same size of giant component and number of single nodes close to our original graph.\n",
    "\n",
    "Except for the <abbr title=\"standard deviation\">std</abbr> parameter, the other parameters come from the Barabási-Albert model. The std parameter can be used to \"shape\" the degree distribution to obtain one similar to our original graph.\n",
    "\n",
    "We chose std by iteration. Here are 3 different degree distibutions (original graph vs *random actor network model*), for 3 values of std.\n",
    "\n",
    "<!-- ![std = 8](assets/anm_degree_distrib_std=8.png) -->\n",
    "\n",
    "![std = 10](https://github.com/swouf/ntds_IMDb_team4/raw/milestone2/assets/anm_degree_distrib_std%3D10.png)\n",
    "\n",
    "![std = 12](https://github.com/swouf/ntds_IMDb_team4/raw/milestone2/assets/anm_degree_distrib_std%3D12.png)\n",
    "\n",
    "![std = 14](https://github.com/swouf/ntds_IMDb_team4/raw/milestone2/assets/anm_degree_distrib_std%3D14.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
